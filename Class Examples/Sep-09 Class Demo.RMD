---
title: "Data Cleaning"
output: word_document
---

1) Import the demonstration data "IPO.csv".
```{r}
ipo.data<-read.csv("ipo.csv",stringsAsFactors = TRUE)
```

2) A quick summary of the data
```{r}
summary(ipo.data)
```

# Outlier Winsorization
Now let's address the issue of outlier
# 1) Check the existense of the outliers
```{r}
with(ipo.data,
     boxplot(Initial.Return))
```
# 2) locate outliers
First, define normal range
```{r}
q1<-with(ipo.data,quantile(Initial.Return,0.25,na.rm=TRUE))
q3<-with(ipo.data,quantile(Initial.Return,0.75,na.rm=TRUE))
range.low<-q1-1.5*(q3-q1)
range.high<-q3+1.5*(q3-q1)
```

Second, identify outliers based on the normal range
Approach 1:
```{r}
ipo.data$outlier.label<-with(ipo.data,
                          ifelse(Initial.Return>range.high,"Outlier",
                           ifelse(Initial.Return<range.low,"Outlier","Normal Data")))
subset(ipo.data,outlier.label=="Outlier")
```

Approach 2:
```{r}
ipo.data[with(ipo.data,which(Initial.Return>range.high|Initial.Return<range.low)),]
```

# 3) Treat Outliers by winsorization
```{r}
ipo.data$Initial.Return.Winsorized<-with(ipo.data,
                          ifelse(Initial.Return>range.high,range.high,
                           ifelse(Initial.Return<range.low,range.low,Initial.Return)))
```

Now check this wisorized Initial Return
```{r}
summary(ipo.data)
```

## Use a function to simplify the work we have done.
```{r}
winsorization<-function(dirty_var){
  q1<-quantile(dirty_var,0.25,na.rm=TRUE)
  q3<-quantile(dirty_var,0.75,na.rm=TRUE)
  upper<-q3+1.5*(q3-q1)
  lower<-q1-1.5*(q3-q1)
  
  cleaned_var<-ifelse(
    dirty_var>upper,upper,
    ifelse(dirty_var<lower, lower,
          dirty_var))
  
  return(cleaned_var)
}
```

We can test this function
```{r}
ipo.data$Price.Revision.Winsorized<-winsorization(ipo.data$Price.Revision)
```

Now check this cleaned data
```{r}
summary(ipo.data)
```

# Some extension:
In the previous demonstration, we define outliers based on the boxplot output. Now consider defining outliers as the mean+/- 3 standard deviaion.

We create a different function to perform the winsorization for this version.
```{r}
winsorization.v2<-function(dirty_var){
  
  upper<-mean(dirty_var,na.rm=TRUE)+3*sd(dirty_var,na.rm=TRUE)
  lower<-mean(dirty_var,na.rm=TRUE)-3*sd(dirty_var,na.rm=TRUE)
  
  cleaned_var<-ifelse(
    dirty_var>upper,upper,
    ifelse(dirty_var<lower, lower,
          dirty_var))
  
  return(cleaned_var)
}
```

Let's check this function
```{r}
ipo.data$Initial.Return.Winsorized.V2<-winsorization.v2(ipo.data$Initial.Return)
summary(ipo.data)
```


# Missing Imputation

We need to perform missing imputation on `Initial.Return.Winsorized`.

## 01) Using unconditional mean

First, calculate the unconditional mean
```{r}
unconditional.mean<-with(ipo.data,mean(Initial.Return.Winsorized,na.rm=TRUE))
```

Second, use the mean to perform the replacing.
```{r}
ipo.data$Initial.Return.Winsorized.Imputed<-with(ipo.data,
     ifelse(is.na(Initial.Return.Winsorized),
       unconditional.mean,
       Initial.Return.Winsorized))
```

Check the cleaned data
```{r}
summary(ipo.data)
```

## 02) Using conditional mean

First, calculate the conditional mean: E(Initial.Return|High.Tech)
```{r}
mean.high<-with(subset(ipo.data,High.Tech=="Yes"),
                mean(Initial.Return.Winsorized,na.rm=TRUE))
mean.low<-with(subset(ipo.data,High.Tech=="No"),
                mean(Initial.Return.Winsorized,na.rm=TRUE))
```

Second, to replace the missing values by the conditional means.
```{r}
ipo.data$Initial.Return.Winsorized.Imputed.V2<-with(ipo.data,
ifelse(
  is.na(Initial.Return.Winsorized)&High.Tech=="Yes",
  mean.high,
  ifelse(
    is.na(Initial.Return.Winsorized)&High.Tech=="No",
    mean.low,
    Initial.Return.Winsorized
  )
)
)
```

Check the output:
```{r}
summary(ipo.data)
```

# Data Partition

The goal is to use simple random sampling to create training and validationd dataset. Training data is used to build model. Validation data is use to evaluate the model.

Assume that we want to create a sample with 200 observations as training dataset, and then use the remaining observations as validation dataset.

Step 1: create random integer for sample selection.
```{r}
set.seed(200)
row_index<-sample(1:nrow(ipo.data),
       200,
       replace=FALSE)
```

Step 2: create training and validation sample
```{r}
train.data<-ipo.data[row_index,]
valid.data<-ipo.data[-row_index,]
```

Check whether training has the same distribution as validation
```{r}
summary(train.data)
summary(valid.data)
```


