---
title: "10 Random Forest"
author: "Prof. Tao Li"
output: pdf_document
---
 
In this demo, I will use the "Adult.csv" data to perform a prediction for ABOVE50K based on the Random Forest algorithm.

# Step 1: Import data and perform data partition
```{r}
dt<-read.csv("adult.csv")
dt_train<-dt[1:18000,]
dt_valid<-dt[-(1:18000),]
```

# Step 2: Build the random forest 
```{r}
library(randomForest)
default_rf<-randomForest(as.factor(ABOVE50K)~.,data=dt_train)
```

Get the output of *defualt_rf*:
```{r}
default_rf
```

Check the convergency of the algorithm
```{r}
plot(default_rf)
```
Check the variable importance:
```{r}
importance(default_rf)
```

variable importance by visualization tools:
```{r}
varImpPlot(default_rf)
```

# Step 3: Customize the Random Forest

Based on the previous regarding the convergency of the *default_rf*, 100 trees seem to be enough to achieve a stable performance. Therefore, we can set ntree=100.
```{r}
oob.err=double()
test.err=double()
for(i in 1:6){
  individual_rf<-randomForest(as.factor(ABOVE50K)~.,data=dt_train,
                              ntree=100,mtry=(i+1))
  # out-of-bag error (based on the imbedded rf output)
  oob.err[i]<-individual_rf$err.rate[100,1]
  # test error (based on the error from valid data)
  pred<-predict(individual_rf,newdata=dt_valid)
  test.err[i]<-1-mean(as.factor(dt_valid$ABOVE50K)==pred)
  # indicate the process 
  cat(i)
}
```

Now, we can check the performance of each individual_rf
```{r}
oob.err
test.err
```

We can plot this performance to get more intuitive understanding
```{r}
matplot(2:7,
        cbind(oob.err,test.err),
        pch=15,
        col=c("red","blue"),
        type="b",
        main="Performance of RF based on different mtry",
        ylab="Error",
        xlab="mtry"
)
```

Based on this chart, it seems that mtry=2 will give the best performance. Therefore, we can create a refined random forecasts by using ntree=100, and mtry=2.

```{r}
refined_rf<-randomForest(as.factor(ABOVE50K)~.,
                         data=dt_train,
                         ntree=100,
                         mtry=2)
refined_rf
```

# Step 4: Prediction with Random Forecasts

By default, predicion is based on categories. However, we can change that into probability.
```{r}
# In-sample
pred_train<-predict(refined_rf,type="prob")[,2]
# Out-of-sample
pred_valid<-predict(refined_rf,newdata=dt_valid, type="prob")[,"1"]

head(pred_train)
head(pred_valid)
```

# Step 5: Performance Evaluation
First define the in-sample actual and out-of-sample actual
```{r}
actual_train<-as.factor(dt_train$ABOVE50K)
actual_valid<-as.factor(dt_valid$ABOVE50K)
```

## Confusion Matrix
In-sample
```{r}
CM_train<-table(actual_train,pred_train>0.5)
CM_train
```
Out-of-sample
```{r}
CM_valid<-table(actual_valid,pred_valid>0.5)
CM_valid
```
## Accuracy, Sensitivity and Specificity
In-sample
```{r}
sum(diag(CM_train))/sum(CM_train)
CM_train[2,2]/sum(CM_train[2,])
CM_train[1,1]/sum(CM_train[1,])
```

In-sample
```{r}
sum(diag(CM_valid))/sum(CM_valid)
CM_valid[2,2]/sum(CM_valid[2,])
CM_valid[1,1]/sum(CM_valid[1,])
```

## ROC Curve and AUC
In-sample
```{r}
library(ROSE)
roc.curve(actual_train,pred_train)
```
Out-of-sample
```{r}
roc.curve(actual_valid,pred_valid)
```

