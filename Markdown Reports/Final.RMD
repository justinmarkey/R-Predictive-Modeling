---
title: "FINAL"
author: "Justin Markey"
date: "12/12/2021"
output: word_document
---
#ncvTest is for heteroscadasticity 

#dwtest is for serial correlation # Conclusion: large p-value, so serial correlation is not a concern. Assumption is satistified.

#shapirotest residuals for normality, also qqnorm and qqline for visual testing


#Import the data

```{r}
defaultdata <- read.csv("Q6.csv")
#defaultdata$Divorce <- ifelse(defaultdata$Divorce=="Urban",1,0)
```


```{r}
lmmodel <-lm(Consumption ~ Income, data = defaultdata)
summary(lmmodel)
# .58
# 2 .60
# 3 .6333
newdata = data.frame(Income = c(75000), Urban = c(1))
predict(lmmodel, newdata)
```


```{r}
defaultdata$Fbs <- factor(defaultdata$Fbs)
defaultdata$RestECG <- factor(defaultdata$RestECG)
defaultdata$ExAng <- factor(defaultdata$ExAng)
defaultdata$Slope <- factor(defaultdata$Slope)
defaultdata$AHD <- ifelse(defaultdata$AHD=="Yes",1,0)

set.seed(347)
row_index<-sample(1:nrow(defaultdata),18000)
train<-defaultdata[row_index,]
valid<-defaultdata[-row_index,]

```

# Libs
```{r}
library(rpart)
library(ROSE)
library(randomForest)
library(gains)
library(lmtest)
library(car)
library(rattle)
```

# Linear
```{r}
linear.model <- lm(data = train, Y )
```

# glm
```{r}
logit.model <- glm(data = defaultdata, Divorce ~ .)
stepwise.mod<-step(logit.model, direction="backward", trace=FALSE)
summary(stepwise.mod)

```

```{r}
cutoff<-0.35
actual<-defaultdata$Divorce
pred<-predict(stepwise.mod, type="response")
confusion.matrix<-table(actual, pred>cutoff)

```

Now, we can calculate accuracy, sensitivity, and specificity.
Approach 1: calculate based on the confusion matrix
```{r}
# Accuracy
sum(diag(confusion.matrix))/sum(confusion.matrix)
# Sensitivity
confusion.matrix[2,2]/sum(confusion.matrix[2,])
# Specificity
confusion.matrix[1,1]/sum(confusion.matrix[1,])
```

```{r}
roc.curve(actual,pred,plotit = FALSE)
```


## analysis
```{r}
lift.table<-gains(actual=actual_y,predicted=pred_y,groups=10)
lift.table$lift[1]
```

# decision tree
```{r}
default.tree<-rpart(data=defaultdata, Divorce~., method="class")
rattle::fancyRpartPlot(default.tree)
```
## analysis
```{r}
default.tree$variable.importance

```

```{r}
outsamplepred <- as.numeric(predict(default.tree)[,"1"])
cutoff_prob = 0.5
roc.curve(actual,pred,plotit = FALSE)
roc.curve(actual, outsamplepred, plotit = FALSE)

mean(ifelse(
    (pred>cutoff_prob&actual==1)|(pred<cutoff_prob&actual==0),
    1,0))
mean(ifelse(
    (outsamplepred>cutoff_prob&actual==1)|(outsamplepred<cutoff_prob&actual==0),
    1,0))
```


## pruning for optimal tree
```{r}
complicated.tree<-rpart(
  data=train,
  ABOVE50K~.,
  method="class",
  control=rpart.control(cp=0.0001))
cp.table<-complicated.tree$cptable

optimal.cp<-cp.table[which.min(cp.table[,"xerror"]),"CP"]
optimal.tree<-prune(complicated.tree, cp=optimal.cp)
```

## measurements
```{r}
outsamplepred <- as.numeric(predict(default.tree,newdata=valid)[,"1"]) #need y =1 probability
outsampleactual<-valid$y
cutoff_prob <- 0.5
# accuracy

mean(ifelse(
    (outsamplepred>cutoff_prob&outsampleactual==1)|(outsamplepred<cutoff_prob&outsampleactual==0),
    1,0))

# sensitivity

sum(ifelse(outsamplepred>cutoff_prob&outsampleactual==1,1,0))/sum(outsampleactual)

# specificity

sum(ifelse(outsamplepred<cutoff_prob&outsampleactual==0,1,0))/(length(outsampleactual)-sum(outsampleactual))
# AUC

roc.curve(outsampleactual, outsmaplepred, plotit=FALSE)
```


# Random Forest
```{r}

default_rf <- randomForest( Y ~.,data=train, ntree=0, mtry = 0)
importance(default_rf)
```
## anaylsis
```{r}
pred_valid<-predict(default_rf,newdata=valid, type="prob")[,"1"]
actual_valid<-as.factor(valid$y)

# CF table

CM_valid<-table(actual_valid,pred_valid>0.5)

# accuracy
sum(diag(CM_valid))/sum(CM_valid)

# sensitivity
CM_valid[2,2]/sum(CM_valid[2,])

# specificity
CM_valid[1,1]/sum(CM_valid[1,])


# auc curve
roc.curve(actual_valid,pred_valid, plotit = FALSE)
```


